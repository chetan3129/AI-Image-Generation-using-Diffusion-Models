# -*- coding: utf-8 -*-
"""AI Image Generator using Diffusion Models.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TiWWPbVa6d6-vM3G-goolhzBEnqudJNe
"""

import torch

from diffusers import StableDiffusionPipeline, EulerAncestralDiscreteScheduler

device = "cuda" if torch.cuda.is_available() else ("mps" if torch.backends.mps.is_available() else "cpu")

model_id = "runwayml/stable-diffusion-v1-5"

pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16 if device == "cuda" else torch.float32)

if device == "cuda":
    pipe = pipe.to(device)
    pipe.enable_attention_slicing()
else:
  pipe.to(device)

prompt = "ultra-detailed portrait of a red fox wearing a tiny scarf, cinematic lighting, 35mm"
negative_prompt = "blurry, lowres, jpeg artifacts, extra fingers, text, watermark"

image = pipe(
    prompt = prompt,
    negative_prompt = negative_prompt,
    num_inference_steps = 30,
    guidance_scale = 7.5,
    height = 512,
    width = 512,
    generator = torch.Generator(device = device).manual_seed(42)).images[0]
image.save("generated_image.png")

image

image_1 = pipe(
    prompt=prompt,
    negative_prompt=negative_prompt,
    num_inference_steps=50,   # sharper details
    guidance_scale=8.0,       # stronger adherence to prompt
    height=768,
    width=768,
    generator=torch.manual_seed(123)
).images[0]

image_1.save("high_quality.png")

image_1

images = pipe(
    prompt=prompt,
    negative_prompt=negative_prompt,
    num_inference_steps=30,
    guidance_scale=7.5,
    height=512,
    width=512,
    num_images_per_prompt=4,   # generate 4 at once
    generator=torch.manual_seed(42)
).images

for i, img in enumerate(images):
    img.save(f"image_{i}.png")